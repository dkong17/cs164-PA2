README file for Programming Assignment 2 (Java edition)
=======================================================

Your directory should now contain the following files:

 build.xml
 README
 cool.lex
 test.cl
 tests/*
 AbstractSymbol.java  -> [course dir]/src/PA2J/AbstractSymbol.java
 BoolConst.java       -> [course dir]/src/PA2J/BoolConst.java
 Flags.java           -> [course dir]/src/PA2J/Flags.java
 IdSymbol.java        -> [course dir]/src/PA2J/IdSymbol.java
 IdTable.java         -> [course dir]/src/PA2J/IdTable.java
 IntSymbol.java       -> [course dir]/src/PA2J/IntSymbol.java
 IntTable.java        -> [course dir]/src/PA2J/IntTable.java
 Lexer.java           -> [course dir]/src/PA2J/Lexer.java
 AbstractTable.java   -> [course dir]/src/PA2J/AbstractTable.java
 StringSymbol.java    -> [course dir]/src/PA2J/StringSymbol.java
 StringTable.java     -> [course dir]/src/PA2J/StringTable.java
 Utilities.java       -> [course dir]/src/PA2J/Utilities.java
 TokenConstants.java  -> [course dir]/src/PA2J/TokenConstants.java
 *.java		      other generated files

	The build.xml contains targets for compiling and running your
	program. DO NOT MODIFY.

	The README contains this info. Part of the assignment is to fill
	the README with the write-up for your project. You should
	explain design decisions, explain why your code is correct, and
	why your test cases are adequate. It is part of the assignment
	to clearly and concisely explain things in text as well as to
	comment your code. Just edit this file.

	cool.lex is a skeleton file for the specification of the
	lexical analyzer. You should complete it with your regular
	expressions, patterns and actions. Information on how to do this
	is in the jlex manual, which is part of your reader.

	test.cl is a COOL program that you can test the lexical
	analyzer on. It contains some errors, so it won't compile with
	coolc. However, test.cl does not exercise all lexical
	constructs of COOL and part of your assignment is to rewrite
	test.cl with a complete set of tests for your lexical analyzer.

        tests is a directory containing five test cases with expected outputs.
        DO NOT MODIFY.

	TokenConstants.java contains constant definitions that are used by
	almost all parts of the compiler. DO NOT MODIFY.

	*Table.java and *Symbol.java contain string table data
	structures.  DO NOT MODIFY.

	Utilities.java contains various support functions used by the
	main lexer driver (Lexer.java).  DO NOT MODIFY.

	Lexer.java contains the main method which will call your lexer
	and print out the tokens that it returns.  DO NOT MODIFY.

        CoolLexer.java is the scanner generated by jlex from cool.lex.
        DO NOT MODIFY IT, as your changes will be overritten the next
        time you run jlex.

	mycoolc is a shell script that glues together the phases of the
	compiler using Unix pipes instead of statically linking code.  
	While inefficient, this architecture makes it easy to mix and match
	the components you write with those of the course compiler.
	DO NOT MODIFY.	

Instructions
------------

	Remember to make sure `~cs164/bin' is in your `path' variable.

	To compile your lexer type:

	% ant lexer

	Run your lexer by putting your test input in a file 'foo.cl' and
	run the lextest program:

	% ./lexer foo.cl

	To run your lexer on the file test.cl type:

	% ant test

        To run five examples in tests directory type:

        % ant test-all

	If you think your lexical analyzer is correct and behaves like
	the one we wrote, you can actually try 'mycoolc' and see whether
	it runs and produces correct code for the examples and your
	first assignment. If your lexical analyzer behaves in an
	unexpected manner, you may get errors anywhere, i.e. during
	parsing, during semantic analysis, during code generation or
	only when you run the produced code on spim. So beware.

	To turnin your work type:

	% ant submit-clean

	And run the "submit" program following the instructions on the
	course web page.
	
	Running "submit" will collect the files cool.lex, test.cl,
	README, and test.output. Don't forget to edit the README file to
	include your write-up, and to write your own test cases in
	test.cl.

 	You may turn in the assignment as many times as you like.
	However, only the last version will be retained for
	grading.

	GOOD LUCK!

---8<------8<------8<------8<---cut here---8<------8<------8<------8<---

Write-up for PA2J
-----------------
	Added were a private field COMMENT_COUNT and states COMMENT, STRING, 
and STRING_ERR. The field was added in order to account for nesting of 
comments enclosed by (*...*). Using a counter allowed the scanner to properly 
enter and exit the COMMENT state. The COMMENT state allowed for the detection of 
unmatched *) error and proper non-tokenization of characters within comment blocks.
Similarly, the STRING state helped find the "boundaries" for the declaration of
string constants. STRING_ERR was a necessary additional states in order to continue
lexing at the proper place after an invalid character was found or the string was
too long.
	All four states (LINE_COMMENT, COMMENT, STRING, STRING_ERR) were added as
cases to the switch for the end-of-file function. Each of the cases returns an
ERROR symbol and reports the pertinent error message.
=======
Added were a private field COMMENT_COUNT and states COMMENT, STRING, 
and STRING_ERR. The field was added in order to account for nesting of 
comments enclosed by (*...*). Using a counter allowed the scanner to go beyond the capabilities
of a regular language and properly enter and exit the COMMENT state. The COMMENT state 
allowed for the detection of unmatched *) error (by only allowing return to YYINITIAL if COMMENT_COUNT were 0)
and proper non-tokenization of characters within  comment blocks. Similarly, the STRING state
helped find the "boundaries" for the declaration of string constants. STRING_ERR was a necessary additional states in order to continue
lexing at the proper place after an invalid character (such as an unescaped newline) was found or the string was
too long. After throwing an error, a \n or \" match in the STRING_ERR state led to a return to YYINITIAL to continue lexing.
	All four states (LINE_COMMENT, COMMENT, STRING, STRING_ERR) were added as
cases to the switch for the end-of-file function. Each of the cases returns an
ERROR symbol and reports the pertinent error message before, like STRING_ERR, returning to YYINITIAL to continue lexing. 
The ERROR symbol, like was mentioned in a Piazza post, allows for lexing to continue and is a sort of 'hack' to the
actual behavior of a typical lexer that allows lexing to skip over an errant token and continue.
	One of the most challenging and caution-inducing components to cool.lex is the correct identification 
of regular expressions and their corresponding subsequent actions (such as adding to a string buffer or changing a state)
being correct. We believe that our tests ensure that our regex strings correctly identify and ensure that we have adhered to
COOL's restrictions.